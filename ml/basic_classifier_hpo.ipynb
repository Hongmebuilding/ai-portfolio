{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb35cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# HPO 를 위한 설정\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ec0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 불러오기\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6067cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 생성\n",
    "df = pd.DataFrame(data = wine.data, columns = wine.feature_names)\n",
    "df['target'] = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6993a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 학습\n",
    "# 특성 (Feature)와 타겟(target) 의 데이터를 분리\n",
    "X = df.drop('target', axis = 1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba826a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터와 테스트 데이터로 분리 (80% 학습, 20% 테스트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f238a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_mannual: 0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "# HyperParameter 를 '수기' 변경\n",
    "clf_mannual = DecisionTreeClassifier(\n",
    "                             criterion = 'entropy', \n",
    "                             max_depth=3,\n",
    "                             min_samples_split=3,\n",
    "                             min_samples_leaf=1,\n",
    "                             splitter='random',\n",
    "                             random_state=4)\n",
    "\n",
    "clf_mannual.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mannual = clf_mannual.predict(X_test)\n",
    "accuracy_mannual = accuracy_score(y_test, y_pred_mannual)\n",
    "print(\"accuracy_mannual:\", accuracy_mannual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "241ad6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameter Tunning\n",
    "# GridSearch를 HyperParameter 를 범위를 한정\n",
    "\n",
    "param_grid = {\n",
    "    \"criterion\" : ['gini', 'entropy'],\n",
    "    \"max_depth\" : [2,3,4,5],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13faf23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper-parameter {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score 0.9224137931034484\n"
     ]
    }
   ],
   "source": [
    "#HPO 및 Fitting\n",
    "clf_grid = DecisionTreeClassifier(random_state= 42)\n",
    "# core\n",
    "grid_search = GridSearchCV(clf_grid, param_grid, cv=5) # 교차 검증 5회\n",
    "# HyperParameter 를 찾고, 이걸 가지고 fitting 이 모두 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyper-parameter\", grid_search.best_params_)\n",
    "print(\"Best Score\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Grid: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# HPO 로 만들어진 모형의 정확도 계산\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_grid = best_model.predict(X_test)\n",
    "accuracy_grid = accuracy_score(y_test, y_pred_grid)\n",
    "print('Accuracy Grid:', accuracy_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c3fa64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "GridSearchCV(\n",
      "    estimator,\n",
      "    param_grid,\n",
      "    *,\n",
      "    scoring=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    n_jobs=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    refit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    cv=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    verbose=\u001b[32m0\u001b[39m,\n",
      "    pre_dispatch=\u001b[33m'2*n_jobs'\u001b[39m,\n",
      "    error_score=nan,\n",
      "    return_train_score=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m     \n",
      "Exhaustive search over specified parameter values for an estimator.\n",
      "\n",
      "Important members are fit, predict.\n",
      "\n",
      "GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      "It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      "\"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      "implemented in the estimator used.\n",
      "\n",
      "The parameters of the estimator used to apply these methods are optimized\n",
      "by cross-validated grid-search over a parameter grid.\n",
      "\n",
      "Read more in the :ref:`User Guide <grid_search>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "estimator : estimator object\n",
      "    This is assumed to implement the scikit-learn estimator interface.\n",
      "    Either estimator needs to provide a ``score`` function,\n",
      "    or ``scoring`` must be passed.\n",
      "\n",
      "param_grid : dict or list of dictionaries\n",
      "    Dictionary with parameters names (`str`) as keys and lists of\n",
      "    parameter settings to try as values, or a list of such\n",
      "    dictionaries, in which case the grids spanned by each dictionary\n",
      "    in the list are explored. This enables searching over any sequence\n",
      "    of parameter settings.\n",
      "\n",
      "scoring : str, callable, list, tuple or dict, default=None\n",
      "    Strategy to evaluate the performance of the cross-validated model on\n",
      "    the test set.\n",
      "\n",
      "    If `scoring` represents a single score, one can use:\n",
      "\n",
      "    - a single string (see :ref:`scoring_parameter`);\n",
      "    - a callable (see :ref:`scoring_callable`) that returns a single value.\n",
      "\n",
      "    If `scoring` represents multiple scores, one can use:\n",
      "\n",
      "    - a list or tuple of unique strings;\n",
      "    - a callable returning a dictionary where the keys are the metric\n",
      "      names and the values are the metric scores;\n",
      "    - a dictionary with metric names as keys and callables as values.\n",
      "\n",
      "    See :ref:`multimetric_grid_search` for an example.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    Number of jobs to run in parallel.\n",
      "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "    for more details.\n",
      "\n",
      "    .. versionchanged:: v0.20\n",
      "       `n_jobs` default changed from 1 to None\n",
      "\n",
      "refit : bool, str, or callable, default=True\n",
      "    Refit an estimator using the best found parameters on the whole\n",
      "    dataset.\n",
      "\n",
      "    For multiple metric evaluation, this needs to be a `str` denoting the\n",
      "    scorer that would be used to find the best parameters for refitting\n",
      "    the estimator at the end.\n",
      "\n",
      "    Where there are considerations other than maximum score in\n",
      "    choosing a best estimator, ``refit`` can be set to a function which\n",
      "    returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      "    case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      "    according to the returned ``best_index_`` while the ``best_score_``\n",
      "    attribute will not be available.\n",
      "\n",
      "    The refitted estimator is made available at the ``best_estimator_``\n",
      "    attribute and permits using ``predict`` directly on this\n",
      "    ``GridSearchCV`` instance.\n",
      "\n",
      "    Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      "    ``best_score_`` and ``best_params_`` will only be available if\n",
      "    ``refit`` is set and all of them will be determined w.r.t this specific\n",
      "    scorer.\n",
      "\n",
      "    See ``scoring`` parameter to know more about multiple metric\n",
      "    evaluation.\n",
      "\n",
      "    See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`\n",
      "    to see how to design a custom selection strategy using a callable\n",
      "    via `refit`.\n",
      "\n",
      "    .. versionchanged:: 0.20\n",
      "        Support for callable added.\n",
      "\n",
      "cv : int, cross-validation generator or an iterable, default=None\n",
      "    Determines the cross-validation splitting strategy.\n",
      "    Possible inputs for cv are:\n",
      "\n",
      "    - None, to use the default 5-fold cross validation,\n",
      "    - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "    - :term:`CV splitter`,\n",
      "    - An iterable yielding (train, test) splits as arrays of indices.\n",
      "\n",
      "    For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "    other cases, :class:`KFold` is used. These splitters are instantiated\n",
      "    with `shuffle=False` so the splits will be the same across calls.\n",
      "\n",
      "    Refer :ref:`User Guide <cross_validation>` for the various\n",
      "    cross-validation strategies that can be used here.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "\n",
      "verbose : int\n",
      "    Controls the verbosity: the higher, the more messages.\n",
      "\n",
      "    - >1 : the computation time for each fold and parameter candidate is\n",
      "      displayed;\n",
      "    - >2 : the score is also displayed;\n",
      "    - >3 : the fold and candidate parameter indexes are also displayed\n",
      "      together with the starting time of the computation.\n",
      "\n",
      "pre_dispatch : int, or str, default='2*n_jobs'\n",
      "    Controls the number of jobs that get dispatched during parallel\n",
      "    execution. Reducing this number can be useful to avoid an\n",
      "    explosion of memory consumption when more jobs get dispatched\n",
      "    than CPUs can process. This parameter can be:\n",
      "\n",
      "    - None, in which case all the jobs are immediately created and spawned. Use\n",
      "      this for lightweight and fast-running jobs, to avoid delays due to on-demand\n",
      "      spawning of the jobs\n",
      "    - An int, giving the exact number of total jobs that are spawned\n",
      "    - A str, giving an expression as a function of n_jobs, as in '2*n_jobs'\n",
      "\n",
      "error_score : 'raise' or numeric, default=np.nan\n",
      "    Value to assign to the score if an error occurs in estimator fitting.\n",
      "    If set to 'raise', the error is raised. If a numeric value is given,\n",
      "    FitFailedWarning is raised. This parameter does not affect the refit\n",
      "    step, which will always raise the error.\n",
      "\n",
      "return_train_score : bool, default=False\n",
      "    If ``False``, the ``cv_results_`` attribute will not include training\n",
      "    scores.\n",
      "    Computing training scores is used to get insights on how different\n",
      "    parameter settings impact the overfitting/underfitting trade-off.\n",
      "    However computing the scores on the training set can be computationally\n",
      "    expensive and is not strictly required to select the parameters that\n",
      "    yield the best generalization performance.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "\n",
      "    .. versionchanged:: 0.21\n",
      "        Default value was changed from ``True`` to ``False``\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "cv_results_ : dict of numpy (masked) ndarrays\n",
      "    A dict with keys as column headers and values as columns, that can be\n",
      "    imported into a pandas ``DataFrame``.\n",
      "\n",
      "    For instance the below given table\n",
      "\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "    |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      "    +============+===========+============+=================+===+=========+\n",
      "    |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "    |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "    |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "    |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      "    +------------+-----------+------------+-----------------+---+---------+\n",
      "\n",
      "    will be represented by a ``cv_results_`` dict of::\n",
      "\n",
      "        {\n",
      "        'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      "                                     mask = [False False False False]...)\n",
      "        'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      "                                    mask = [ True  True False False]...),\n",
      "        'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      "                                     mask = [False False  True  True]...),\n",
      "        'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      "        'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      "        'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      "        'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      "        'rank_test_score'    : [2, 4, 3, 1],\n",
      "        'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      "        'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      "        'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      "        'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      "        'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      "        'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      "        'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      "        'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      "        'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      "        }\n",
      "\n",
      "    NOTE\n",
      "\n",
      "    The key ``'params'`` is used to store a list of parameter\n",
      "    settings dicts for all the parameter candidates.\n",
      "\n",
      "    The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      "    ``std_score_time`` are all in seconds.\n",
      "\n",
      "    For multi-metric evaluation, the scores for all the scorers are\n",
      "    available in the ``cv_results_`` dict at the keys ending with that\n",
      "    scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      "    above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      "\n",
      "best_estimator_ : estimator\n",
      "    Estimator that was chosen by the search, i.e. estimator\n",
      "    which gave highest score (or smallest loss if specified)\n",
      "    on the left out data. Not available if ``refit=False``.\n",
      "\n",
      "    See ``refit`` parameter for more information on allowed values.\n",
      "\n",
      "best_score_ : float\n",
      "    Mean cross-validated score of the best_estimator\n",
      "\n",
      "    For multi-metric evaluation, this is present only if ``refit`` is\n",
      "    specified.\n",
      "\n",
      "    This attribute is not available if ``refit`` is a function.\n",
      "\n",
      "best_params_ : dict\n",
      "    Parameter setting that gave the best results on the hold out data.\n",
      "\n",
      "    For multi-metric evaluation, this is present only if ``refit`` is\n",
      "    specified.\n",
      "\n",
      "best_index_ : int\n",
      "    The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      "    candidate parameter setting.\n",
      "\n",
      "    The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      "    the parameter setting for the best model, that gives the highest\n",
      "    mean score (``search.best_score_``).\n",
      "\n",
      "    For multi-metric evaluation, this is present only if ``refit`` is\n",
      "    specified.\n",
      "\n",
      "scorer_ : function or a dict\n",
      "    Scorer function used on the held out data to choose the best\n",
      "    parameters for the model.\n",
      "\n",
      "    For multi-metric evaluation, this attribute holds the validated\n",
      "    ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      "\n",
      "n_splits_ : int\n",
      "    The number of cross-validation splits (folds/iterations).\n",
      "\n",
      "refit_time_ : float\n",
      "    Seconds used for refitting the best model on the whole dataset.\n",
      "\n",
      "    This is present only if ``refit`` is not False.\n",
      "\n",
      "    .. versionadded:: 0.20\n",
      "\n",
      "multimetric_ : bool\n",
      "    Whether or not the scorers compute several metrics.\n",
      "\n",
      "classes_ : ndarray of shape (n_classes,)\n",
      "    The classes labels. This is present only if ``refit`` is specified and\n",
      "    the underlying estimator is a classifier.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`. Only defined if\n",
      "    `best_estimator_` is defined (see the documentation for the `refit`\n",
      "    parameter for more details) and that `best_estimator_` exposes\n",
      "    `n_features_in_` when fit.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Only defined if\n",
      "    `best_estimator_` is defined (see the documentation for the `refit`\n",
      "    parameter for more details) and that `best_estimator_` exposes\n",
      "    `feature_names_in_` when fit.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      "train_test_split : Utility function to split the data into a development\n",
      "    set usable for fitting a GridSearchCV instance and an evaluation set\n",
      "    for its final evaluation.\n",
      "sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      "    loss function.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The parameters selected are those that maximize the score of the left out\n",
      "data, unless an explicit score is passed in which case it is used instead.\n",
      "\n",
      "If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      "reasons if individual jobs take very little time, but may raise errors if\n",
      "the dataset is large and not enough memory is available.  A workaround in\n",
      "this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "`pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "n_jobs`.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn import svm, datasets\n",
      ">>> from sklearn.model_selection import GridSearchCV\n",
      ">>> iris = datasets.load_iris()\n",
      ">>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      ">>> svc = svm.SVC()\n",
      ">>> clf = GridSearchCV(svc, parameters)\n",
      ">>> clf.fit(iris.data, iris.target)\n",
      "GridSearchCV(estimator=SVC(),\n",
      "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      ">>> sorted(clf.cv_results_.keys())\n",
      "['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " 'param_C', 'param_kernel', 'params',...\n",
      " 'rank_test_score', 'split0_test_score',...\n",
      " 'split2_test_score', ...\n",
      " 'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "\u001b[31mFile:\u001b[39m           ~/ai/ai-portfolio/ml/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py\n",
      "\u001b[31mType:\u001b[39m           ABCMeta\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f541bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
